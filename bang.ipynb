{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from kiwipiepy import Kiwi\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import ElectraModel, ElectraTokenizer\n",
    "from transformers import ElectraForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSemanticSegmentation, TrainingArguments, Trainer\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 에 넣기 위한 dataset 생성 class\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def read_data(path):\n",
    "    survey = pd.read_csv(path, index_col=0)\n",
    "    survey.fillna(0, inplace=True)\n",
    "    survey = survey.reset_index()\n",
    "    return survey\n",
    "\n",
    "# 최소한의 전처리\n",
    "def cleaned_content(text):\n",
    "    d = re.sub('\\n', '. ', text) # 줄바꿈 > .\n",
    "    d = re.sub('[^가-힣0-9a-zA-Z ]{2,}', \".\", d) # 특수문자 두개 이상인거 .으로 변경\n",
    "    return d\n",
    "\n",
    "# 키위 전처리\n",
    "def kiwi_clean(text):\n",
    "    kiwi = Kiwi()\n",
    "    get_kiwi_pos = ['NNG', 'NP', 'NNP', 'MM', 'VV', 'VV-I', 'VV-R', 'VA', 'VA-I', 'VA-R', 'VCP', 'VCN', 'MAG', 'MAJ', 'XR']\n",
    "    kiwi_lem = []\n",
    "    for word in kiwi.tokenize(text):\n",
    "        if word.tag in get_kiwi_pos:\n",
    "            kiwi_lem.append(word.lemma)\n",
    "        else:\n",
    "            kiwi_lem.append('')\n",
    "    fin_txt = [txt for txt in kiwi_lem if txt != '']\n",
    "    return ' '.join(fin_txt)\n",
    "\n",
    "# 조사한 데이터 전체 정리\n",
    "def get_data():\n",
    "    # survey data 선언\n",
    "    survey_data = read_data(\"./data/survey.csv\")\n",
    "    # content_id 중에서 댓글이 같이 추가된 데이터 정리하기\n",
    "    survey_data['content_id'] = survey_data['content_id'].apply(lambda x: x.split(',')[0] if len(str(x)) > 6 else x)\n",
    "    # content_id 가 0인 데이터 제외하기 -> 추후 merge를 위해 content_id 모두 int type으로 변경\n",
    "    survey_data = survey_data[survey_data['content_id'] != 0].reset_index().drop(columns=['index'])\n",
    "    survey_data['content_id'] = survey_data['content_id'].astype(int)\n",
    "    survey_data = survey_data[['content_id', 'guide', 'light', 'interior', 'story', 'probability', 'creativity', 'production', 'activity', 'scale', 'fear', 'device', 'fun', 'service']]\n",
    "    # 전체 review data 불러오기\n",
    "    review_all = pd.read_csv(\"./data/reviews.csv\", index_col=0) \n",
    "    # 전체 review data 중에서 survey data에 있는 댓글만 가져오기\n",
    "    survey_content = review_all.loc[review_all['id'].isin(survey_data['content_id'])][['id', 'content']]\n",
    "    survey_content.columns = ['content_id', 'content']\n",
    "    # survey, content merge 하기\n",
    "    fin_data = pd.merge(survey_content, survey_data, on='content_id', how='left')\n",
    "    fin_data = fin_data.drop_duplicates()\n",
    "    return fin_data\n",
    "\n",
    "def clean_kiwi_data():\n",
    "    fin_df = get_data()\n",
    "    fin_df['content'] = fin_df['content'].apply(cleaned_content)\n",
    "    fin_df['content'] = fin_df['content'].apply(kiwi_clean)\n",
    "    return fin_df\n",
    "\n",
    "def clean_min_data():\n",
    "    fin_df = get_data()\n",
    "    fin_df['content'] = fin_df['content'].apply(cleaned_content)\n",
    "    return fin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content</th>\n",
       "      <th>guide</th>\n",
       "      <th>light</th>\n",
       "      <th>interior</th>\n",
       "      <th>story</th>\n",
       "      <th>probability</th>\n",
       "      <th>creativity</th>\n",
       "      <th>production</th>\n",
       "      <th>activity</th>\n",
       "      <th>scale</th>\n",
       "      <th>fear</th>\n",
       "      <th>device</th>\n",
       "      <th>fun</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>513069</td>\n",
       "      <td>인 나쁘다 인테리어 문제 이다 각각 장치 작동 법 스스로 터득 되다 기본 어렵다 한...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>505540</td>\n",
       "      <td>칠포루바토 맞다 진짜 웃기다 신기 장치 가득가득 테</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500819</td>\n",
       "      <td>괜히 칠바토 칠바토 그러다 아니다 방 탈 많이 하다 이거 평점 높다</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480104</td>\n",
       "      <td>인 오다 강남 흙 길 루바토 이다</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>479813</td>\n",
       "      <td>이탬 루바토 이다 리뷰 보다 처음 장난 이다 하지만 옵저버 한 더 하다 이 태다 보...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>475313</td>\n",
       "      <td>방리 이 가다 무난하다 탈출</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>461591</td>\n",
       "      <td>인 동생 은근 무섭다 기억</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>458794</td>\n",
       "      <td>조 어이없다</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>440808</td>\n",
       "      <td>기록 초기 방 탈출 테마 입문</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>202572</td>\n",
       "      <td>혼방 마지막 문제 노후 갓 문제 이다 알다 별짓 다 하다 자명 문제 이다 장치 너프...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5013 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      content_id                                            content  guide  \\\n",
       "0         513069  인 나쁘다 인테리어 문제 이다 각각 장치 작동 법 스스로 터득 되다 기본 어렵다 한...    0.0   \n",
       "1         505540                       칠포루바토 맞다 진짜 웃기다 신기 장치 가득가득 테    0.0   \n",
       "2         500819              괜히 칠바토 칠바토 그러다 아니다 방 탈 많이 하다 이거 평점 높다    0.0   \n",
       "3         480104                                 인 오다 강남 흙 길 루바토 이다    0.0   \n",
       "4         479813  이탬 루바토 이다 리뷰 보다 처음 장난 이다 하지만 옵저버 한 더 하다 이 태다 보...    0.0   \n",
       "...          ...                                                ...    ...   \n",
       "5018      475313                                    방리 이 가다 무난하다 탈출    0.0   \n",
       "5019      461591                                     인 동생 은근 무섭다 기억    0.0   \n",
       "5020      458794                                             조 어이없다    0.0   \n",
       "5021      440808                                   기록 초기 방 탈출 테마 입문    0.0   \n",
       "5022      202572  혼방 마지막 문제 노후 갓 문제 이다 알다 별짓 다 하다 자명 문제 이다 장치 너프...    0.0   \n",
       "\n",
       "      light  interior  story  probability  creativity  production  activity  \\\n",
       "0       0.0       1.0    0.0          0.0         1.0         0.0       0.0   \n",
       "1       0.0       0.0    0.0          0.0         1.0         0.0       0.0   \n",
       "2       0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "3       0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "4       0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "...     ...       ...    ...          ...         ...         ...       ...   \n",
       "5018    0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "5019    0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "5020    0.0       0.0    0.0         -1.0         0.0         0.0       0.0   \n",
       "5021    0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "5022    0.0       1.0   -1.0          0.0         0.0         0.0       0.0   \n",
       "\n",
       "      scale  fear  device  fun  service  \n",
       "0       0.0   0.0     0.0  0.0      0.0  \n",
       "1       0.0   0.0     1.0  0.0      0.0  \n",
       "2       0.0   0.0     0.0  0.0      0.0  \n",
       "3       0.0   0.0     0.0  0.0      0.0  \n",
       "4       0.0   0.0     0.0  0.0      0.0  \n",
       "...     ...   ...     ...  ...      ...  \n",
       "5018    0.0   0.0     0.0  0.0      0.0  \n",
       "5019    0.0   1.0     0.0  0.0      0.0  \n",
       "5020    0.0   0.0     0.0  0.0      0.0  \n",
       "5021    0.0   0.0     0.0  0.0      0.0  \n",
       "5022    0.0   0.0    -1.0  1.0      0.0  \n",
       "\n",
       "[5013 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_data = clean_kiwi_data()\n",
    "clear_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content</th>\n",
       "      <th>guide</th>\n",
       "      <th>light</th>\n",
       "      <th>interior</th>\n",
       "      <th>story</th>\n",
       "      <th>probability</th>\n",
       "      <th>creativity</th>\n",
       "      <th>production</th>\n",
       "      <th>activity</th>\n",
       "      <th>scale</th>\n",
       "      <th>fear</th>\n",
       "      <th>device</th>\n",
       "      <th>fun</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>513069</td>\n",
       "      <td>2인 / 나쁘지 않은 인테리어와 문제지만 각각의 장치들의 작동법을 스스로 터득해야 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>505540</td>\n",
       "      <td>칠포루바토 맞네! 진짜 웃기고 신기한 장치들이 가득가득한 테.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500819</td>\n",
       "      <td>괜히 칠바토 칠바토 그러는게 아니었네 나름 방탈 많이 했지만 이건 평점 높게 줄 만 하다</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480104</td>\n",
       "      <td>#344 4인 와 강남 흙길계의 루바토다</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>479813</td>\n",
       "      <td>With 이탬 Gp루바토라는 리뷰를 보고 처음엔 장난이겠지 싶었다 하지만 옵저버로 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>475313</td>\n",
       "      <td>방린이들끼리 가서 무난하게 탈출</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>461591</td>\n",
       "      <td>2인) 동생이랑. 은근 무서웠던거로 기억.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>458794</td>\n",
       "      <td>조나 어이없음 .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>440808</td>\n",
       "      <td>(기록용) 초기 방탈출테마, 입문용</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>202572</td>\n",
       "      <td>혼방4 / 마지막 문제 노후화로 갓문제인줄 알고 별짓을 다했는데 자명한 문제였다. ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5013 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      content_id                                            content  guide  \\\n",
       "0         513069  2인 / 나쁘지 않은 인테리어와 문제지만 각각의 장치들의 작동법을 스스로 터득해야 ...    0.0   \n",
       "1         505540                 칠포루바토 맞네! 진짜 웃기고 신기한 장치들이 가득가득한 테.    0.0   \n",
       "2         500819  괜히 칠바토 칠바토 그러는게 아니었네 나름 방탈 많이 했지만 이건 평점 높게 줄 만 하다    0.0   \n",
       "3         480104                             #344 4인 와 강남 흙길계의 루바토다    0.0   \n",
       "4         479813  With 이탬 Gp루바토라는 리뷰를 보고 처음엔 장난이겠지 싶었다 하지만 옵저버로 ...    0.0   \n",
       "...          ...                                                ...    ...   \n",
       "5018      475313                                  방린이들끼리 가서 무난하게 탈출    0.0   \n",
       "5019      461591                            2인) 동생이랑. 은근 무서웠던거로 기억.    0.0   \n",
       "5020      458794                                          조나 어이없음 .    0.0   \n",
       "5021      440808                                (기록용) 초기 방탈출테마, 입문용    0.0   \n",
       "5022      202572  혼방4 / 마지막 문제 노후화로 갓문제인줄 알고 별짓을 다했는데 자명한 문제였다. ...    0.0   \n",
       "\n",
       "      light  interior  story  probability  creativity  production  activity  \\\n",
       "0       0.0       1.0    0.0          0.0         1.0         0.0       0.0   \n",
       "1       0.0       0.0    0.0          0.0         1.0         0.0       0.0   \n",
       "2       0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "3       0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "4       0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "...     ...       ...    ...          ...         ...         ...       ...   \n",
       "5018    0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "5019    0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "5020    0.0       0.0    0.0         -1.0         0.0         0.0       0.0   \n",
       "5021    0.0       0.0    0.0          0.0         0.0         0.0       0.0   \n",
       "5022    0.0       1.0   -1.0          0.0         0.0         0.0       0.0   \n",
       "\n",
       "      scale  fear  device  fun  service  \n",
       "0       0.0   0.0     0.0  0.0      0.0  \n",
       "1       0.0   0.0     1.0  0.0      0.0  \n",
       "2       0.0   0.0     0.0  0.0      0.0  \n",
       "3       0.0   0.0     0.0  0.0      0.0  \n",
       "4       0.0   0.0     0.0  0.0      0.0  \n",
       "...     ...   ...     ...  ...      ...  \n",
       "5018    0.0   0.0     0.0  0.0      0.0  \n",
       "5019    0.0   1.0     0.0  0.0      0.0  \n",
       "5020    0.0   0.0     0.0  0.0      0.0  \n",
       "5021    0.0   0.0     0.0  0.0      0.0  \n",
       "5022    0.0   0.0    -1.0  1.0      0.0  \n",
       "\n",
       "[5013 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_min_data = clean_min_data()\n",
    "clear_min_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train 코드 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인 및 train, test 분리\n",
    "def split_data(target):\n",
    "    fin_data = pd.read_csv(\"./data/minbang_final.csv\", index_col=0)\n",
    "    final_target = fin_data[['content', target]]\n",
    "    final_target = final_target.dropna()\n",
    "    train_data = final_target.sample(frac=0.8, random_state=42)\n",
    "    test_data = final_target.drop(train_data.index)\n",
    "    return train_data, test_data\n",
    "\n",
    "# 분류 모델에 넣기 위해서 1차원으로 구성된 세 개의 클래스를 2차원으로 재구성 후 label 로 투입\n",
    "# -1(부정)=0, 0(중립)=1, 1(긍정)=2\n",
    "\n",
    "def resize_label(target):\n",
    "    train_data, test_data = split_data(target)\n",
    "    train_label = []\n",
    "    for label in train_data[target].values:\n",
    "        if label == -1:\n",
    "            train_label.append([1., 0., 0.])\n",
    "        elif label == 0:\n",
    "            train_label.append([0., 1., 0.])\n",
    "        elif label == 1:\n",
    "            train_label.append([0., 0., 1.])\n",
    "\n",
    "    test_label = []\n",
    "    for label in test_data[target].values:\n",
    "        if label == 0:\n",
    "            test_label.append([0., 1., 0.])\n",
    "        elif label == -1:\n",
    "            test_label.append([1., 0., 0.])\n",
    "        elif label == 1:\n",
    "            test_label.append([0., 0., 1.])\n",
    "    \n",
    "    return train_label, test_label\n",
    "\n",
    "def add_token(path):\n",
    "    tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "    # 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "    with open(path, \"r\") as add:\n",
    "        add_data = add.read()\n",
    "    addword = add_data.split('\\n')\n",
    "    # token에 새로운 단어 추가 \n",
    "    tokenizer.add_tokens(addword)\n",
    "    # token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "    # 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    return tokenizer\n",
    "\n",
    "def content_tokenize(target):\n",
    "    train_data, test_data = split_data(target)\n",
    "    train_label, test_label = resize_label(target)\n",
    "    \n",
    "    # train content 토큰화\n",
    "    tokenized_train_sentences = tokenizer(\n",
    "        list(train_data['content']),\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=128,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "\n",
    "    # test content 토큰화\n",
    "    tokenized_test_sentences = tokenizer(\n",
    "        list(test_data['content']),\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=128,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return tokenized_train_sentences, tokenized_test_sentences\n",
    "\n",
    "def final_trainer(target, path, epoch, train_batch, eval_batch):\n",
    "    train_data, test_data = split_data(target)\n",
    "    train_label, test_label = resize_label(target)\n",
    "    tokenized_train_sentences, tokenized_test_sentences = content_tokenize(target)\n",
    "    # bert 모델에 데이터가 들어갈 수 있게 만들어 둔 class를 활용하여 train, test dataset 생성\n",
    "    train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "    test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "    \n",
    "    # hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련시킬 때 사용되는 객체 설정 부분\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = f'./model/{target}/{path}/chech_point',    # 모델과 훈련 중 생성되는 파일이 저장될 디렉토리 경로\n",
    "        num_train_epochs = epoch,              # 훈련 epoch 수\n",
    "        per_device_train_batch_size = train_batch,    # 장치에 할당된 훈련 배치 크기\n",
    "        per_device_eval_batch_size = eval_batch,    # 장치에 할당된 평가 배치 크기, 모델을 평가할 때 사용되는 배치 크기\n",
    "        logging_dir = f'./model/{target}/{path}/logs',             # 훈련 중 로그 파일이 저장될 디렉토리\n",
    "        logging_steps = 500,                # 로그 출력 빈도, 500 step에 한 번씩 출력 예정\n",
    "        save_total_limit = 2,               # 체크포인트 파일 저장 제한 수\n",
    "    )\n",
    "\n",
    "    # hugging face 의 trasformers 라이브러리를 사용하여 모델 훈련하고 관리하는 객체 설정 부분\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "    )\n",
    "\n",
    "    # train 진행\n",
    "    trainer.train() \n",
    "    # train 완료 정보 저장\n",
    "    trainer.save_model(f\"./model/{target}/{path}/model\")\n",
    "    tokenizer.save_pretrained(f\"./model/{target}/{path}/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 사전학습된 bert 모델 사용\n",
    "# num_labels 클래스에 대해서 훈련을 하기 위해서 num_labels=3 할당함, problem_type=\"multi_label_classification\" 를 통해서 모델이 다중 레이블 분류에 해당함을 명시\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-small-v3-discriminator\", num_labels=3, problem_type=\"multi_label_classification\")\n",
    "tokenizer = add_token(\"./data/add_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['guide', 'light', 'interior', 'story', 'probability', 'creativity', 'production', 'activity', 'scale', 'fear', 'device', 'fun', 'service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [01:27<?, ?it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2149, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [02:54<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1215, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [04:21<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1064, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [05:47<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0852, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [07:14<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0666, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [08:41<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0537, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [10:07<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0462, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [11:34<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0411, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [13:01<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0374, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [14:28<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0307, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [15:54<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0327, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [17:20<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0274, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [18:47<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.026, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [20:13<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0227, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "  0%|          | 0/13 [21:39<?, ?it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0219, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                      \n",
      "100%|██████████| 7530/7530 [21:43<00:00,  5.78it/s]\n",
      "  8%|▊         | 1/13 [21:44<4:20:56, 1304.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1303.8367, 'train_samples_per_second': 92.266, 'train_steps_per_second': 5.775, 'train_loss': 0.06217362636114022, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [23:11<4:20:56, 1304.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0766, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [24:39<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0757, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [26:06<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0741, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [27:33<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0758, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [29:00<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0745, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [30:27<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0742, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [31:53<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0749, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [33:19<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0754, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [34:46<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0745, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [36:13<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0756, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [37:39<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0725, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [39:06<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0732, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [40:32<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0774, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [42:02<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0736, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "  8%|▊         | 1/13 [43:30<4:20:56, 1304.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0732, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      "100%|██████████| 7530/7530 [21:51<00:00,  5.74it/s]\n",
      " 15%|█▌        | 2/13 [43:36<4:00:00, 1309.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1311.4082, 'train_samples_per_second': 91.733, 'train_steps_per_second': 5.742, 'train_loss': 0.07478256200255942, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      " 15%|█▌        | 2/13 [45:06<4:00:00, 1309.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1691, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      " 15%|█▌        | 2/13 [46:35<4:00:00, 1309.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0788, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      " 15%|█▌        | 2/13 [48:05<4:00:00, 1309.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0767, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      " 15%|█▌        | 2/13 [49:35<4:00:00, 1309.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.078, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      " 15%|█▌        | 2/13 [51:05<4:00:00, 1309.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0758, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      " 15%|█▌        | 2/13 [52:37<4:00:00, 1309.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0765, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      " 15%|█▌        | 2/13 [54:06<4:00:00, 1309.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0767, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      " 15%|█▌        | 2/13 [55:37<4:00:00, 1309.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0776, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      " 15%|█▌        | 2/13 [57:04<4:00:00, 1309.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0723, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      " 15%|█▌        | 2/13 [58:34<4:00:00, 1309.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0684, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                  \n",
      " 15%|█▌        | 2/13 [1:00:05<4:00:00, 1309.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0629, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 15%|█▌        | 2/13 [1:01:36<4:00:00, 1309.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0623, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 15%|█▌        | 2/13 [1:03:07<4:00:00, 1309.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0612, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 15%|█▌        | 2/13 [1:04:38<4:00:00, 1309.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0546, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 15%|█▌        | 2/13 [1:06:09<4:00:00, 1309.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0543, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      "100%|██████████| 7530/7530 [22:37<00:00,  5.55it/s]]\n",
      " 23%|██▎       | 3/13 [1:06:15<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1357.9392, 'train_samples_per_second': 88.59, 'train_steps_per_second': 5.545, 'train_loss': 0.07619876929646628, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:07:47<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1733, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:09:18<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1243, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:10:48<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1202, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:12:17<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1147, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:13:47<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1093, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:15:15<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.104, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:16:42<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0998, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:18:10<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0969, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:19:38<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0952, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:21:06<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.094, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:22:35<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0907, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:24:03<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0877, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:25:30<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0829, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:26:57<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.079, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 23%|██▎       | 3/13 [1:28:25<3:41:57, 1331.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0769, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      "100%|██████████| 7530/7530 [22:15<00:00,  5.64it/s]]\n",
      " 31%|███       | 4/13 [1:28:31<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1335.3566, 'train_samples_per_second': 90.088, 'train_steps_per_second': 5.639, 'train_loss': 0.10314728469645992, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:30:00<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1255, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:31:29<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1211, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:32:58<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1215, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:34:27<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1216, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:35:56<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1213, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:37:25<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1174, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:38:53<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1231, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:40:22<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1184, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:41:51<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1201, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:43:20<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1185, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:44:49<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1099, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:46:18<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1003, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:47:47<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0909, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:49:15<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0828, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 31%|███       | 4/13 [1:50:44<3:20:01, 1333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0813, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      "100%|██████████| 7530/7530 [22:18<00:00,  5.63it/s]]\n",
      " 38%|███▊      | 5/13 [1:50:50<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1338.1177, 'train_samples_per_second': 89.902, 'train_steps_per_second': 5.627, 'train_loss': 0.11144930436158403, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [1:52:19<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1487, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [1:53:48<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1443, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [1:55:17<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1432, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [1:56:45<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1386, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [1:58:15<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0865, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [1:59:44<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0711, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [2:01:13<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0631, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [2:02:41<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0614, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [2:04:09<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0534, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [2:05:37<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.052, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [2:07:05<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0472, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [2:08:33<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0441, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [2:10:01<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0383, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [2:11:28<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0343, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 38%|███▊      | 5/13 [2:12:56<2:58:03, 1335.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0363, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      "100%|██████████| 7530/7530 [22:11<00:00,  5.66it/s]]\n",
      " 46%|████▌     | 6/13 [2:13:02<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1331.0122, 'train_samples_per_second': 90.382, 'train_steps_per_second': 5.657, 'train_loss': 0.0773428715557691, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:14:30<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1848, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:15:58<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1333, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:17:26<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1175, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:18:55<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.106, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:20:23<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.091, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:21:51<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0812, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:23:20<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0768, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:24:48<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0667, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:26:17<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0594, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:27:45<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0593, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:29:13<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0517, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:30:41<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0535, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:32:09<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.054, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:33:37<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0503, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 46%|████▌     | 6/13 [2:35:06<2:35:39, 1334.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0516, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      "100%|██████████| 7530/7530 [22:08<00:00,  5.67it/s]]\n",
      " 54%|█████▍    | 7/13 [2:35:12<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1328.9422, 'train_samples_per_second': 90.523, 'train_steps_per_second': 5.666, 'train_loss': 0.08229313957422062, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:36:41<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1318, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:38:09<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1282, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:39:38<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1289, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:41:06<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1269, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:42:35<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1304, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:44:04<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1231, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:45:32<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0805, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:47:00<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0537, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:48:28<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0434, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:49:56<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0408, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:51:24<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0398, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:52:53<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0368, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:54:22<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0372, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:55:50<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0309, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 54%|█████▍    | 7/13 [2:57:19<2:13:16, 1332.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0342, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      "100%|██████████| 7530/7530 [22:12<00:00,  5.65it/s]]\n",
      " 62%|██████▏   | 8/13 [2:57:25<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1332.4841, 'train_samples_per_second': 90.283, 'train_steps_per_second': 5.651, 'train_loss': 0.07751279582144571, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [2:58:54<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.124, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:00:24<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0767, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:01:53<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0658, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:03:22<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0597, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:04:51<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0546, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:06:20<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0506, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:07:50<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.052, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:09:19<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0481, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:10:48<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0484, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:12:17<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0436, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:13:46<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0384, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:15:16<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0345, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:16:45<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.029, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:18:14<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0268, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 62%|██████▏   | 8/13 [3:19:43<1:51:04, 1332.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0259, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      "100%|██████████| 7530/7530 [22:22<00:00,  5.61it/s]]\n",
      " 69%|██████▉   | 9/13 [3:19:49<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1342.9162, 'train_samples_per_second': 89.581, 'train_steps_per_second': 5.607, 'train_loss': 0.05172244807480183, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:21:18<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2015, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:22:47<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1913, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:24:16<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1732, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:25:45<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1429, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:27:14<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1292, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:28:44<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1224, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:30:13<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1124, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:31:42<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0972, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:33:11<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0864, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:34:41<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.071, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:36:10<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0615, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:37:39<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0556, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:39:07<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0531, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:40:36<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.051, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      " 69%|██████▉   | 9/13 [3:42:05<1:29:05, 1336.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0478, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                    \n",
      "100%|██████████| 7530/7530 [22:21<00:00,  5.61it/s]]\n",
      " 77%|███████▋  | 10/13 [3:42:11<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1341.5686, 'train_samples_per_second': 89.671, 'train_steps_per_second': 5.613, 'train_loss': 0.10619354898711125, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [3:43:41<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2752, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [3:45:10<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2615, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [3:46:40<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2606, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [3:48:09<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2609, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [3:49:39<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2622, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [3:51:08<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2612, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [3:52:37<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2599, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [3:54:06<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2592, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [3:55:35<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2619, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [3:57:05<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2433, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [3:58:34<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1448, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [4:00:03<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1242, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [4:01:31<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1119, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [4:03:01<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1027, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      " 77%|███████▋  | 10/13 [4:04:30<1:06:54, 1338.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0977, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                     \n",
      "100%|██████████| 7530/7530 [22:23<00:00,  5.60it/s]t]\n",
      " 85%|████████▍ | 11/13 [4:04:36<44:40, 1340.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1343.8106, 'train_samples_per_second': 89.522, 'train_steps_per_second': 5.603, 'train_loss': 0.2120808962965075, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:06:06<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3527, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:07:34<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2502, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:09:03<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2311, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:10:32<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2169, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:12:01<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1981, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:13:30<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1864, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:15:00<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1701, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:16:29<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1598, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:17:58<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1511, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:19:26<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1433, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:20:56<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1286, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:22:26<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1201, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:23:55<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.113, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:25:25<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1167, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 85%|████████▍ | 11/13 [4:26:54<44:40, 1340.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1095, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      "100%|██████████| 7530/7530 [22:23<00:00,  5.61it/s]\n",
      " 92%|█████████▏| 12/13 [4:27:00<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1343.3834, 'train_samples_per_second': 89.55, 'train_steps_per_second': 5.605, 'train_loss': 0.17619330978013606, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:28:29<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0986, 'learning_rate': 4.6679946879150064e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:29:58<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0926, 'learning_rate': 4.335989375830013e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:31:27<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0838, 'learning_rate': 4.00398406374502e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:32:56<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0517, 'learning_rate': 3.671978751660027e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:34:25<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0359, 'learning_rate': 3.339973439575033e-05, 'epoch': 9.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:35:55<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0302, 'learning_rate': 3.00796812749004e-05, 'epoch': 11.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:37:24<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0247, 'learning_rate': 2.6759628154050465e-05, 'epoch': 13.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:38:54<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0227, 'learning_rate': 2.3439575033200534e-05, 'epoch': 15.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:40:23<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0186, 'learning_rate': 2.01195219123506e-05, 'epoch': 17.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:41:53<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0177, 'learning_rate': 1.6799468791500664e-05, 'epoch': 19.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:43:22<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0182, 'learning_rate': 1.3479415670650731e-05, 'epoch': 21.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:44:51<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0145, 'learning_rate': 1.0159362549800798e-05, 'epoch': 23.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:46:21<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0153, 'learning_rate': 6.839309428950863e-06, 'epoch': 25.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:47:50<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0154, 'learning_rate': 3.51925630810093e-06, 'epoch': 27.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      " 92%|█████████▏| 12/13 [4:49:18<22:21, 1341.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0136, 'learning_rate': 1.99203187250996e-07, 'epoch': 29.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/314qsssd1p718wry9j0bh9000000gn/T/ipykernel_94299/3185649175.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                   \n",
      "100%|██████████| 7530/7530 [22:23<00:00,  5.60it/s]\n",
      "100%|██████████| 13/13 [4:49:24<00:00, 1335.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1343.6507, 'train_samples_per_second': 89.532, 'train_steps_per_second': 5.604, 'train_loss': 0.03685577344767759, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for category in tqdm(category_names):\n",
    "    final_trainer(category, '2', 30, 16, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pred 코드 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_data = pd.read_csv('./data/minbang_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_token(target, path):\n",
    "    tokenizer = ElectraTokenizer.from_pretrained(f\"./model/{target}/{path}/tokenizer\")\n",
    "    # 토큰에 추가할 단어 -> '방탈출'이라는 도메인 지시기에 근거한 용어, 분리되어서는 안 되기 때문에 별도로 추가 작업 진행\n",
    "    with open(\"./data/add_data.txt\", \"r\") as add:\n",
    "        add_data = add.read()\n",
    "    addword = add_data.split('\\n')\n",
    "    # token에 새로운 단어 추가 \n",
    "    tokenizer.add_tokens(addword)\n",
    "    # token에 단어 추가후 기존 모델의 임베딩 레이어에 추가한 단어에 대한 임베딩 벡터가 없을 수 있기 때문\n",
    "    # 아래 코드를 통해서 토큰의 개수가 변했음을 모델에 알리고 모델의 임베딩 레이어를 조정하여 새로운 토큰을 수용할 수 있게 함\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    return tokenizer\n",
    "\n",
    "def read_saved_model(target, path):\n",
    "    # 저장된 모델과 토크나이저를 불러오기\n",
    "    model_path = f\"./model/{target}/{path}/model\"\n",
    "    model = ElectraForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = add_new_token(target, path)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "# 함수 정의\n",
    "def classify_text(text):\n",
    "    # 문장을 토큰화하고 모델에 입력으로 전달\n",
    "    text = cleaned_content(text)\n",
    "    text = kiwi_clean(text)\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "# 함수 정의\n",
    "def classify_clear_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 확률값 계산\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # 가장 높은 확률값에 해당하는 클래스 선택\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "    \n",
    "def change_num(num):\n",
    "    if num == 0:\n",
    "        return (-1)\n",
    "    elif num == 1:\n",
    "        return 0\n",
    "    elif num == 2:\n",
    "        return 1\n",
    "\n",
    "def pred_data(target, path):\n",
    "    train_data, test_data = split_data(target)\n",
    "    model, tokenizer = read_saved_model(target, path)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    # print(test_data)\n",
    "    \n",
    "    pred_list = []\n",
    "    for sent in test_data['content']:\n",
    "        # print(sent)\n",
    "        pred, _ = classify_clear_text(sent)\n",
    "        pred_list.append(pred)\n",
    "\n",
    "    test_data['pred'] = pred_list\n",
    "    test_data['pred'] = test_data['pred'].apply(change_num)\n",
    "    print(f'{target} 0포함 예측률', '\\n', classification_report(test_data[target], test_data['pred']))\n",
    "    \n",
    "    test_data2 = test_data[test_data[target] != 0]\n",
    "    print(f'{target} 0제외 예측률', '\\n', classification_report(test_data2[target], test_data2['pred']))\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  8%|▊         | 1/13 [00:10<02:10, 10.90s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guide 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00        31\n",
      "         0.0       0.96      0.99      0.98       963\n",
      "         1.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.95      1003\n",
      "   macro avg       0.32      0.33      0.33      1003\n",
      "weighted avg       0.92      0.95      0.94      1003\n",
      "\n",
      "guide 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00      31.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       9.0\n",
      "\n",
      "    accuracy                           0.00      40.0\n",
      "   macro avg       0.00      0.00      0.00      40.0\n",
      "weighted avg       0.00      0.00      0.00      40.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 15%|█▌        | 2/13 [00:21<02:00, 10.98s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00        14\n",
      "         0.0       0.98      0.99      0.99       988\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.98      1003\n",
      "   macro avg       0.33      0.33      0.33      1003\n",
      "weighted avg       0.97      0.98      0.97      1003\n",
      "\n",
      "light 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00      14.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00      15.0\n",
      "   macro avg       0.00      0.00      0.00      15.0\n",
      "weighted avg       0.00      0.00      0.00      15.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 23%|██▎       | 3/13 [00:33<01:51, 11.19s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interior 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         6\n",
      "         0.0       0.92      0.99      0.95       921\n",
      "         1.0       0.00      0.00      0.00        76\n",
      "\n",
      "    accuracy                           0.91      1003\n",
      "   macro avg       0.31      0.33      0.32      1003\n",
      "weighted avg       0.84      0.91      0.88      1003\n",
      "\n",
      "interior 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       6.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      76.0\n",
      "\n",
      "    accuracy                           0.00      82.0\n",
      "   macro avg       0.00      0.00      0.00      82.0\n",
      "weighted avg       0.00      0.00      0.00      82.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 31%|███       | 4/13 [00:44<01:40, 11.21s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.33      0.08      0.13        24\n",
      "         0.0       0.88      1.00      0.93       880\n",
      "         1.0       0.00      0.00      0.00        99\n",
      "\n",
      "    accuracy                           0.88      1003\n",
      "   macro avg       0.40      0.36      0.36      1003\n",
      "weighted avg       0.78      0.88      0.82      1003\n",
      "\n",
      "story 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      0.08      0.15        24\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.00      0.00      0.00        99\n",
      "\n",
      "    accuracy                           0.02       123\n",
      "   macro avg       0.33      0.03      0.05       123\n",
      "weighted avg       0.20      0.02      0.03       123\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 38%|███▊      | 5/13 [00:56<01:30, 11.37s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00        33\n",
      "         0.0       0.96      0.99      0.97       959\n",
      "         1.0       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.95      1003\n",
      "   macro avg       0.32      0.33      0.32      1003\n",
      "weighted avg       0.91      0.95      0.93      1003\n",
      "\n",
      "probability 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00      33.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      11.0\n",
      "\n",
      "    accuracy                           0.00      44.0\n",
      "   macro avg       0.00      0.00      0.00      44.0\n",
      "weighted avg       0.00      0.00      0.00      44.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 46%|████▌     | 6/13 [01:07<01:19, 11.41s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creativity 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         5\n",
      "         0.0       0.95      0.99      0.97       952\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.94      1003\n",
      "   macro avg       0.32      0.33      0.32      1003\n",
      "weighted avg       0.90      0.94      0.92      1003\n",
      "\n",
      "creativity 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       5.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      46.0\n",
      "\n",
      "    accuracy                           0.00      51.0\n",
      "   macro avg       0.00      0.00      0.00      51.0\n",
      "weighted avg       0.00      0.00      0.00      51.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 54%|█████▍    | 7/13 [01:19<01:09, 11.53s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "production 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         4\n",
      "         0.0       0.92      0.99      0.96       928\n",
      "         1.0       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.92      1003\n",
      "   macro avg       0.31      0.33      0.32      1003\n",
      "weighted avg       0.86      0.92      0.89      1003\n",
      "\n",
      "production 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       4.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      71.0\n",
      "\n",
      "    accuracy                           0.00      75.0\n",
      "   macro avg       0.00      0.00      0.00      75.0\n",
      "weighted avg       0.00      0.00      0.00      75.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 62%|██████▏   | 8/13 [01:31<00:58, 11.62s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         4\n",
      "         0.0       0.96      0.99      0.98       961\n",
      "         1.0       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.95      1003\n",
      "   macro avg       0.32      0.33      0.33      1003\n",
      "weighted avg       0.92      0.95      0.93      1003\n",
      "\n",
      "activity 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       4.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      38.0\n",
      "\n",
      "    accuracy                           0.00      42.0\n",
      "   macro avg       0.00      0.00      0.00      42.0\n",
      "weighted avg       0.00      0.00      0.00      42.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 69%|██████▉   | 9/13 [01:43<00:47, 11.78s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00        31\n",
      "         0.0       0.93      0.99      0.96       938\n",
      "         1.0       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.93      1003\n",
      "   macro avg       0.31      0.33      0.32      1003\n",
      "weighted avg       0.87      0.93      0.90      1003\n",
      "\n",
      "scale 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00      31.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      34.0\n",
      "\n",
      "    accuracy                           0.00      65.0\n",
      "   macro avg       0.00      0.00      0.00      65.0\n",
      "weighted avg       0.00      0.00      0.00      65.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 77%|███████▋  | 10/13 [01:55<00:35, 11.74s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00        11\n",
      "         0.0       0.94      0.99      0.97       948\n",
      "         1.0       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.94      1003\n",
      "   macro avg       0.31      0.33      0.32      1003\n",
      "weighted avg       0.89      0.94      0.92      1003\n",
      "\n",
      "fear 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00      11.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      44.0\n",
      "\n",
      "    accuracy                           0.00      55.0\n",
      "   macro avg       0.00      0.00      0.00      55.0\n",
      "weighted avg       0.00      0.00      0.00      55.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 85%|████████▍ | 11/13 [02:07<00:23, 11.88s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00        72\n",
      "         0.0       0.89      0.99      0.94       889\n",
      "         1.0       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.88      1003\n",
      "   macro avg       0.30      0.33      0.31      1003\n",
      "weighted avg       0.78      0.88      0.83      1003\n",
      "\n",
      "device 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00      72.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      42.0\n",
      "\n",
      "    accuracy                           0.00     114.0\n",
      "   macro avg       0.00      0.00      0.00     114.0\n",
      "weighted avg       0.00      0.00      0.00     114.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 92%|█████████▏| 12/13 [02:19<00:11, 11.89s/it]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fun 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00        13\n",
      "         0.0       0.80      0.99      0.88       800\n",
      "         1.0       0.00      0.00      0.00       190\n",
      "\n",
      "    accuracy                           0.79      1003\n",
      "   macro avg       0.27      0.33      0.29      1003\n",
      "weighted avg       0.64      0.79      0.71      1003\n",
      "\n",
      "fun 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00      13.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00     190.0\n",
      "\n",
      "    accuracy                           0.00     203.0\n",
      "   macro avg       0.00      0.00      0.00     203.0\n",
      "weighted avg       0.00      0.00      0.00     203.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/Bang/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 13/13 [02:31<00:00, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service 0포함 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         9\n",
      "         0.0       0.98      0.99      0.99       982\n",
      "         1.0       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.97      1003\n",
      "   macro avg       0.33      0.33      0.33      1003\n",
      "weighted avg       0.96      0.97      0.97      1003\n",
      "\n",
      "service 0제외 예측률 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       9.0\n",
      "         0.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00      12.0\n",
      "\n",
      "    accuracy                           0.00      21.0\n",
      "   macro avg       0.00      0.00      0.00      21.0\n",
      "weighted avg       0.00      0.00      0.00      21.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "category_names = ['guide', 'light', 'interior', 'story', 'probability', 'creativity', 'production', 'activity', 'scale', 'fear', 'device', 'fun', 'service']\n",
    "for category in tqdm(category_names):\n",
    "    pred_data(category, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_electra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
